{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrian0s/ML4NLP1-2023-Tutorial-Notebooks/blob/main/exercises/ex1_given.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saGgI3Olu95J"
      },
      "source": [
        "# ML4NLP1\n",
        "## Starting Point for Exercise 1, part I\n",
        "\n",
        "This notebook is supposed to serve as a starting point and/or inspiration when starting exercise 1.\n",
        "\n",
        "One of the goals of this exercise is o make you acquainted with sklearn and related libraries like pandas and numpy. You will probably need to consult the documentation of those libraries:\n",
        "- sklearn: [Documentation](https://scikit-learn.org/stable/user_guide.html)\n",
        "- Pandas: [Documentation](https://pandas.pydata.org/docs/#)\n",
        "- Numpy: [Documentation](https://numpy.org/doc/)\n",
        "\n",
        "**Importing files to Google Colab:** If you have never used Colab or never uploaded a file to Colab, quickly skim over an introduction: [Introduction on medium](https://medium.com/@master_yi/importing-datasets-in-google-colab-c816fc654f97).\n",
        "\n",
        "We're using the second method mentioned in the blogpost: (1) upload the four files `x_train.txt` and `y_train.txt`, `x_test.txt` and `y_test.txt` to a directory in Google Drive and (2) adjust the paths in the second cell to point to your uploaded files.\n",
        "\n",
        "Then execute the first cell to give Colab permission to access the two files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tdRJ0jEu95M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import string\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03G0aWf8u95N"
      },
      "outputs": [],
      "source": [
        "def read_from_path(path):\n",
        "    with open(path) as f:\n",
        "        return f.read().splitlines()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3Bl0cNzu95O"
      },
      "outputs": [],
      "source": [
        "x_train = read_from_path('wili-2018/x_train.txt')\n",
        "y_train = read_from_path('wili-2018/y_train.txt')\n",
        "x_test = read_from_path('wili-2018/x_test.txt')\n",
        "y_test = read_from_path('wili-2018/y_test.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxgyFHw7u95O"
      },
      "outputs": [],
      "source": [
        "# combine x_train and y_train into one dataframe\n",
        "train_df = pd.DataFrame({'text': x_train, 'label': y_train})\n",
        "# write train_df to csv with tab as separator\n",
        "train_df.to_csv('train_df.csv', index=False, sep='\\t')\n",
        "# comibne x_test and y_test into one dataframe\n",
        "test_df = pd.DataFrame({'text': x_test, 'label': y_test})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZNh6jkuu95O",
        "outputId": "96bb0643-6357-4887-c1cb-98a59653c59a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['pan', 'eus', 'arg', 'che', 'koi', 'tet', 'mon', 'cdo', 'min', 'mhr', 'roa-tara', 'yor', 'eng', 'egl', 'ara', 'afr', 'kin', 'xmf', 'deu', 'pol']\n"
          ]
        }
      ],
      "source": [
        "# get list of all labels\n",
        "labels = train_df['label'].unique().tolist()\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fedggZhUu95P"
      },
      "outputs": [],
      "source": [
        "# T: Have a quick peek at the training data, looking at a couple of texts from different languages. Do you notice anything that might be challenging for the classification?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceEKVnz3u95P"
      },
      "outputs": [],
      "source": [
        "# T: How many instances per label are there in the training and test set? Do you think this is a balanced dataset? Do you think the train/test split is appropriate? If not, please rearrange the data in a more appropriate way.\n",
        "train_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO4KTRxzu95Q"
      },
      "outputs": [],
      "source": [
        "# T: Get a subset of the train/test data that includes English, German, Dutch, Danish, Swedish and Norwegian, plus 20 additional languages of your choice (the labels can be found in the file labels.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXU1KDfxu95R"
      },
      "outputs": [],
      "source": [
        "# T: With the following code, we wanted to encode the labels, however, our cat was walking on the keyboard and some of it got changed. Can you fix it?\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_fitted = LabelEncoder().fit(train_df['label'])\n",
        "y_train_dev, y_test = le_fitted.fit(train_df['label']), le_fitted.fit(test_df['label'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dyslexia-chinese",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}